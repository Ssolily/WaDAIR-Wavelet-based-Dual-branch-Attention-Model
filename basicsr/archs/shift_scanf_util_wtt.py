import time
import torch
from einops import rearrange
import numpy as np


def generate_scan_indices(shape, scan_len, mode="row"):
    B, C, H, W = shape
    total_patches = H * W
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    coords = torch.arange(total_patches, device=device).reshape(H, W)

    if mode == "row":
        scan_order = coords.reshape(-1)
    elif mode == "column":
        scan_order = coords.permute(1, 0).reshape(-1)
    elif mode == "diagonal":
        scan_order = []
        for d in range(H + W - 1):
            for i in range(H):
                j = d - i
                if 0 <= j < W:
                    scan_order.append(coords[i, j])
        scan_order = torch.stack(scan_order)
    else:
        raise ValueError(f"Invalid scan mode: {mode}")

    # Pad scan_order if not divisible
    pad_len = (scan_len - (total_patches % scan_len)) % scan_len
    if pad_len > 0:
        pad = scan_order[-pad_len:]  # Repeat last few indices
        scan_order = torch.cat([scan_order, pad], dim=0)

    num_chunks = scan_order.numel() // scan_len
    scan_ids = scan_order.reshape(num_chunks, scan_len)

    # Inverse ids: used to reorder patches after scanning
    inverse_ids = torch.argsort(scan_ids.reshape(-1)).reshape(scan_ids.shape)

    return scan_ids, inverse_ids

def mair_row_ids_generate(shape, scan_len):
    return generate_scan_indices(shape, scan_len, mode="row")

def mair_column_ids_generate(shape, scan_len):
    return generate_scan_indices(shape, scan_len, mode="column")

def mair_diagonal_ids_generate(shape, scan_len):
    return generate_scan_indices(shape, scan_len, mode="diagonal")



def mair_ids_scan(inp, scan_ids, bkdl=False):
    '''
    Args:
        inp: Tensor of shape [B, C, H, W]
        scan_ids: Tensor of shape [num_chunks, scan_len] (generated by row/column/diagonal id generator)
        bkdl: whether to output for backward (flattened version)

    Returns:
        Tensor of shape [B, num_chunks, scan_len * C] or [B, 1, C, total_tokens] (if bkdl=True)
    '''
    B, C, H, W = inp.shape
    inp = inp.reshape(B, C, -1)  # [B, C, H*W]
    scan_ids = scan_ids.to(inp.device)  # [num_chunks, scan_len]

    # Expand scan_ids to [B, num_chunks, scan_len] for batched gather
    scan_ids = scan_ids.unsqueeze(0).expand(B, -1, -1)  # [B, num_chunks, scan_len]
    scan_ids = scan_ids.reshape(B, -1)  # [B, num_chunks * scan_len]

    # Gather tokens
    gathered = torch.gather(inp, 2, scan_ids.unsqueeze(1).expand(-1, C, -1))  # [B, C, num_chunks * scan_len]

    if bkdl:
        return gathered.unsqueeze(1)  # [B, 1, C, L]
    else:
        gathered = gathered.reshape(B, C, -1, scan_ids.shape[-1] // scan_ids.shape[1])  # [B, C, num_chunks, scan_len]
        gathered = gathered.permute(0, 2, 3, 1).reshape(B, scan_ids.shape[1] // scan_ids.shape[1], -1)  # [B, num_chunks, scan_len * C]
        return gathered

def mair_ids_inverse(inp, inverse_ids, shape, original_L=None):
    B, _, C, L_all = inp.shape
    _, _, H, W = shape
    total_len = H * W

    x = inp.squeeze(1)  # [B, C, L_all]
    idx = inverse_ids.reshape(-1).to(x.device)  # [L_all or longer]

    if original_L is not None:
        idx = idx[:original_L]
        x = x[..., :original_L]
        total_len = original_L

    # ⚠️ 修剪掉非法 index（越界）
    mask = idx < total_len
    idx = idx[mask]
    x = x[..., mask]

    assert x.shape[-1] == idx.shape[-1], f"x length {x.shape[-1]} != index length {idx.shape[-1]}"
    assert idx.max() < total_len, f"idx.max={idx.max()} >= total_len={total_len}"

    out = torch.zeros(B, C, total_len, device=x.device, dtype=x.dtype)
    out = out.scatter(2, idx.unsqueeze(0).unsqueeze(0).expand(B, C, -1), x)

    return out.view(B, C, H, W)



if __name__ == '__main__':
    # torch.set_default_device(1)
    start_time = time.time()

    end_time = time.time()

    print(f"函数运行时间：{end_time - start_time} 秒")
